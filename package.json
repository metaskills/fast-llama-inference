{
  "name": "fast-llama-inference",
  "version": "0.1.0",
  "private": true,
  "type": "module",
  "scripts": {
    "build": "rm -rf dist && npx tsc",
    "chat": "node dist/chat.js",
    "tools": "node dist/tools.js",
    "demo": "node dist/demo.js",
    "evalExtractClaims": "node dist/evals/extractClaims.js",
    "evalVerifyClaim": "node dist/evals/verifyClaim.js"
  },
  "dependencies": {
    "@ai-sdk/amazon-bedrock": "^1.0.6",
    "@ai-sdk/groq": "^1.0.9",
    "@ai-sdk/openai": "^1.0.11",
    "@vercel/otel": "^1.10.0",
    "ai": "^4.0.22",
    "autoevals": "^0.0.111",
    "braintrust": "^0.0.177",
    "dotenv": "^16.4.7",
    "inquirer": "^12.3.0",
    "zod": "^3.24.1"
  },
  "devDependencies": {
    "typescript": "^5.7.2"
  }
}
